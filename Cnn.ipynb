{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('data/fashion_train.npy', mmap_mode='r')\n",
    "data_test = np.load('data/fashion_test.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, **INPUT):\n",
    "\n",
    "        # Inherit from nn module\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Define activation function\n",
    "        self.af = INPUT.get('af')\n",
    "\n",
    "        # Define drop ratio\n",
    "        self.dpr = INPUT.get('dpr')\n",
    "\n",
    "        # Define neural network architecture\n",
    "        self.nn = nn.Sequential(\n",
    "                # C1 6@28x28\n",
    "                nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "                nn.BatchNorm2d(6),\n",
    "                self.af(),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                \n",
    "                # C2: 16@10x10\n",
    "                nn.Dropout(self.dpr),\n",
    "                nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "                nn.BatchNorm2d(16),\n",
    "                self.af(),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                \n",
    "                # Apply flattening on the output\n",
    "                nn.Flatten(),\n",
    "                \n",
    "                # Dense part\n",
    "                # L1\n",
    "                nn.Dropout(self.dpr),\n",
    "                nn.Linear(16 * 5 * 5, 120),\n",
    "                nn.BatchNorm1d(120),\n",
    "                self.af(),\n",
    "                \n",
    "                # L2\n",
    "                nn.Dropout(self.dpr),\n",
    "                nn.Linear(120, 84),\n",
    "                nn.BatchNorm1d(84),\n",
    "                self.af(),\n",
    "                \n",
    "                # L3\n",
    "                nn.Dropout(self.dpr),\n",
    "                nn.Linear(84, 10))\n",
    "        \n",
    "        # Define batch size\n",
    "        self.batch_size = INPUT.get('batch_size')\n",
    "\n",
    "        # Define datasets\n",
    "        self.training_data = DataLoader(\n",
    "            INPUT.get('trd'), batch_size=self.batch_size, shuffle=True, num_workers=1)\n",
    "        self.validation_data = DataLoader(\n",
    "            INPUT.get('vd'), batch_size=self.batch_size, shuffle=True, num_workers=1)\n",
    "        self.test_data = DataLoader(\n",
    "            INPUT.get('ted'), batch_size=self.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        # Define loss function\n",
    "        self.loss_fn = INPUT.get('loss_fn')\n",
    "\n",
    "        # Define learning rate\n",
    "        self.lr = INPUT.get('lr')\n",
    "\n",
    "        # Define numper of epochs\n",
    "        self.epochs = INPUT.get('epochs')\n",
    "\n",
    "        # Define optimizer\n",
    "        self.optimizer = INPUT.get('optim')(self.parameters(), lr=self.lr)\n",
    "\n",
    "        # Save training progress\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.nn(x)\n",
    "        return logits\n",
    "    \n",
    "    def train_loop(self):\n",
    "        \n",
    "        size = len(self.training_data.dataset)\n",
    "        for batch, (X, y) in enumerate(self.training_data):\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            pred = self.forward(X)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    def val_loop(self):\n",
    "        size = len(self.validation_data.dataset)\n",
    "        num_batches = len(self.validation_data)\n",
    "        test_loss, correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.validation_data:\n",
    "                pred = self.forward(X)\n",
    "                test_loss += self.loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "\n",
    "        print(\n",
    "            f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "        # Save it to history\n",
    "        self.acc_history.append(correct)\n",
    "        self.loss_history.append(test_loss)\n",
    "\n",
    "    def visualize(self):\n",
    "        x = [i for i in range(self.epochs)]\n",
    "        y1 = self.acc_history\n",
    "        y2 = self.loss_history\n",
    "        plt.plot(x, y1)\n",
    "        plt.plot(x, y2)\n",
    "        plt.show()\n",
    "\n",
    "    def fit(self):\n",
    "        for t in range(self.epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            self.train_loop()\n",
    "            self.val_loop()\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        return softmax(logits).argmax(1)\n",
    "\n",
    "    def test(self):\n",
    "        # Get data\n",
    "        X, y = next(iter(self.test_data))\n",
    "\n",
    "        # Predict values\n",
    "        y_hat = self.predict(X)\n",
    "\n",
    "        print(\"Accuracy score for test data\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"Acc: {accuracy_score(y, y_hat)*100} %\")\n",
    "        print()\n",
    "        print(\"Confusion matrix for test data\")\n",
    "        print(\"-\"*60)\n",
    "        print(confusion_matrix(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Initialize model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m INPUT \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m100\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrd\u001b[39m\u001b[39m'\u001b[39m: training_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m model \u001b[39m=\u001b[39m CNN(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mINPUT)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model\u001b[39m.\u001b[39mfit()\n",
      "\u001b[1;32m/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_data \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     INPUT\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtrd\u001b[39m\u001b[39m'\u001b[39m), batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_data \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     INPUT\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvd\u001b[39m\u001b[39m'\u001b[39m), batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_data \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     INPUT\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mted\u001b[39;49m\u001b[39m'\u001b[39;49m), batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, num_workers\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m# Define loss function\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juliehagen/Library/CloudStorage/OneDrive-ITU/Machine_Learning/Clothing_classification-/Cnn.ipynb#X21sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn \u001b[39m=\u001b[39m INPUT\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mloss_fn\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/utils/data/dataloader.py:349\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 349\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/utils/data/sampler.py:139\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement, \u001b[39mbool\u001b[39m):\n\u001b[1;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.10/site-packages/torch/utils/data/sampler.py:146\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_samples\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[39m# dataset size might change at runtime\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_source)\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split training into  training and validation\n",
    "g_cpu = torch.Generator()\n",
    "g_cpu.manual_seed(3)\n",
    "training_data, val_data = torch.utils.data.random_split(data_train, [50000, 10000])\n",
    "\n",
    "# Initialize model\n",
    "INPUT = {\n",
    "    'batch_size': 100,\n",
    "    'trd': training_data,\n",
    "    'vd': val_data,\n",
    "    #'ted': test_data,\n",
    "    'loss_fn': nn.CrossEntropyLoss(),\n",
    "    'lr': 1e-1,\n",
    "    'epochs': 5,\n",
    "    'af': nn.Sigmoid,\n",
    "    'optim': torch.optim.Adam,\n",
    "    'dpr': 1e-3\n",
    "\n",
    "}\n",
    "model = CNN(**INPUT)\n",
    "\n",
    "# Train model\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
