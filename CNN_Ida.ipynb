{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, activation_fn, drop_out_rate, batch_size, epochs, train_data, val_data, test_data, loss_fn, lr, optimizer):\n",
    "\n",
    "        # Inherit from nn module\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # Define activation function\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "        # Define drop ratio\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "\n",
    "        # Define neural network architecture\n",
    "        self.nn = nn.Sequential(\n",
    "                # C1 6@28x28\n",
    "                nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "                nn.BatchNorm2d(6),\n",
    "                self.activation_fn(),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                \n",
    "                # C2: 16@10x10\n",
    "                nn.Dropout(self.drop_out_rate),\n",
    "                nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "                nn.BatchNorm2d(16),\n",
    "                self.activation_fn(),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                \n",
    "                # Apply flattening on the output\n",
    "                nn.Flatten(),\n",
    "                \n",
    "                # Dense part\n",
    "                # L1\n",
    "                nn.Dropout(self.drop_out_rate),\n",
    "                nn.Linear(16 * 5 * 5, 120),\n",
    "                nn.BatchNorm1d(120),\n",
    "                self.activation_fn(),\n",
    "                \n",
    "                # L2\n",
    "                nn.Dropout(self.drop_out_rate),\n",
    "                nn.Linear(120, 84),\n",
    "                nn.BatchNorm1d(84),\n",
    "                self.activation_fn(),\n",
    "                \n",
    "                # L3\n",
    "                nn.Dropout(self.drop_out_rate),\n",
    "                nn.Linear(84, 10))\n",
    "        \n",
    "        # Define batch size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Define numper of epochs\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Define datasets\n",
    "        self.training_data = DataLoader(\n",
    "            train_data, batch_size=self.batch_size, shuffle=True, num_workers=1)\n",
    "        self.validation_data = DataLoader(\n",
    "            val_data, batch_size=self.batch_size, shuffle=True, num_workers=1)\n",
    "        self.test_data = DataLoader(\n",
    "            test_data, batch_size=len(test_data), shuffle=True, num_workers=1)\n",
    "\n",
    "        # Define loss function\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        # Define learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "        # Define optimizer\n",
    "        self.optimizer = optimizer(self.parameters(), lr=self.lr)\n",
    "\n",
    "        # Save training progress\n",
    "        self.loss_history = []\n",
    "        self.acc_history = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.nn(x)\n",
    "        return logits\n",
    "    \n",
    "    def train_loop(self):\n",
    "        size = len(self.training_data.dataset)\n",
    "        for batch, (X, y) in enumerate(self.training_data):\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            pred = self.forward(X)\n",
    "            loss = self.loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if batch % 20 == 0:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    def val_loop(self):\n",
    "        size = len(self.validation_data.dataset)\n",
    "        num_batches = len(self.validation_data)\n",
    "        test_loss, correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.validation_data:\n",
    "                pred = self.forward(X)\n",
    "                test_loss += self.loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "\n",
    "        print(\n",
    "            f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "        # Save it to history\n",
    "        self.acc_history.append(correct)\n",
    "        self.loss_history.append(test_loss)\n",
    "\n",
    "    def fit(self):\n",
    "        for t in range(self.epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            self.train_loop()\n",
    "            self.val_loop()\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        return softmax(logits).argmax(1)\n",
    "\n",
    "    def test(self):\n",
    "        # Get data\n",
    "        X, y = next(iter(self.test_data))\n",
    "\n",
    "        # Predict values\n",
    "        y_hat = self.predict(X)\n",
    "\n",
    "        print(\"Accuracy score for test data\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"Acc: {accuracy_score(y, y_hat)*100} %\")\n",
    "        print()\n",
    "        print(\"Confusion matrix for test data\")\n",
    "        print(\"-\"*60)\n",
    "        print(confusion_matrix(y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_train = np.load('data/fashion_train.npy', mmap_mode='r')\n",
    "data_test = np.load('data/fashion_test.npy', mmap_mode='r')\n",
    "\n",
    "X_train = data_train[:, :-1]\n",
    "y_train = data_train[:, -1]\n",
    "\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "y_train_tensor = torch.Tensor(y_train).long()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long) \n",
    "\n",
    "# Reshape X_train and X_test for convolutional input (assuming 28x28 images)\n",
    "X_train_tensor = X_train_tensor.view(-1, 1, 28, 28)  # Adjust dimensions based on your actual image size\n",
    "X_test_tensor = X_test_tensor.view(-1, 1, 28, 28)  # Adjust dimensions based on your actual image size\n",
    "\n",
    "\n",
    "# Create TensorDataset\n",
    "data_train = TensorDataset(X_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training into training and validation\n",
    "g_cpu = torch.Generator()\n",
    "g_cpu.manual_seed(3)\n",
    "data_train, data_val = torch.utils.data.random_split(data_train, [8000, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input = {'activation_fn': nn.Sigmoid,\n",
    "         'drop_out_rate': 0.,\n",
    "         'batch_size': 100, \n",
    "         'epochs': 10, \n",
    "         'train_data': data_train, \n",
    "         'val_data': data_val, \n",
    "         'test_data': data_test, \n",
    "         'loss_fn': nn.CrossEntropyLoss(), \n",
    "         'lr': 0.1, \n",
    "         'optimizer': torch.optim.Adam \n",
    "         }\n",
    "model = CNN(input['activation_fn'], \n",
    "            input['drop_out_rate'], \n",
    "            input['batch_size'], \n",
    "            input['epochs'], \n",
    "            input['train_data'], \n",
    "            input['val_data'], \n",
    "            input['test_data'], \n",
    "            input['loss_fn'], \n",
    "            input['lr'], \n",
    "            input['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.151961  [    0/ 8000]\n",
      "loss: 1.117417  [ 2000/ 8000]\n",
      "loss: 0.505964  [ 4000/ 8000]\n",
      "loss: 0.642222  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.642387 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.404509  [    0/ 8000]\n",
      "loss: 0.534760  [ 2000/ 8000]\n",
      "loss: 0.565140  [ 4000/ 8000]\n",
      "loss: 0.581934  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.510328 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.445292  [    0/ 8000]\n",
      "loss: 0.556170  [ 2000/ 8000]\n",
      "loss: 0.427615  [ 4000/ 8000]\n",
      "loss: 0.492390  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.471627 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.348552  [    0/ 8000]\n",
      "loss: 0.378745  [ 2000/ 8000]\n",
      "loss: 0.456573  [ 4000/ 8000]\n",
      "loss: 0.444900  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.410467 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.400454  [    0/ 8000]\n",
      "loss: 0.428064  [ 2000/ 8000]\n",
      "loss: 0.380284  [ 4000/ 8000]\n",
      "loss: 0.463567  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.390441 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.281386  [    0/ 8000]\n",
      "loss: 0.369601  [ 2000/ 8000]\n",
      "loss: 0.315782  [ 4000/ 8000]\n",
      "loss: 0.382142  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.388133 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.293288  [    0/ 8000]\n",
      "loss: 0.376745  [ 2000/ 8000]\n",
      "loss: 0.297398  [ 4000/ 8000]\n",
      "loss: 0.396628  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.361125 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.256633  [    0/ 8000]\n",
      "loss: 0.341218  [ 2000/ 8000]\n",
      "loss: 0.495169  [ 4000/ 8000]\n",
      "loss: 0.273284  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.367426 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.341240  [    0/ 8000]\n",
      "loss: 0.248063  [ 2000/ 8000]\n",
      "loss: 0.344440  [ 4000/ 8000]\n",
      "loss: 0.298533  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.362547 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.252371  [    0/ 8000]\n",
      "loss: 0.240441  [ 2000/ 8000]\n",
      "loss: 0.353405  [ 4000/ 8000]\n",
      "loss: 0.274342  [ 6000/ 8000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.359825 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
